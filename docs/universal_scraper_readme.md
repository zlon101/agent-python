# Universal Web Scraper - é€šç”¨ç½‘é¡µæ•°æ®æŠ“å–å™¨

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

é€šç”¨ç½‘é¡µæ•°æ®æŠ“å–å™¨æ˜¯ä¸€ä¸ªå¼ºå¤§ã€çµæ´»çš„æ•°æ®é‡‡é›†å·¥å…·ï¼Œå®Œå…¨æ»¡è¶³ä½ æå‡ºçš„éœ€æ±‚ï¼š

âœ… **æ”¯æŒè‡ªå®šä¹‰å­—æ®µå’ŒCSSé€‰æ‹©å™¨**  
âœ… **æ”¯æŒåˆ†é¡µæŠ“å–ï¼ˆæŒ‰é’®/URLå‚æ•°ï¼‰**  
âœ… **å¯é…ç½®é¡µç èŒƒå›´å’Œå»¶è¿Ÿæ—¶é—´**  
âœ… **è¾“å‡ºæ ‡å‡†JSONæ ¼å¼**  
âœ… **ä¸LangChain Agentæ— ç¼é›†æˆ**

---

## ğŸ“‹ éœ€æ±‚å®ç°

æ ¹æ®ä½ çš„éœ€æ±‚ï¼š

### è¾“å…¥å‚æ•°
- âœ… ç½‘å€ï¼ˆurlï¼‰
- âœ… éœ€è¦è§£æçš„DOMå†…å®¹ï¼ˆå­—æ®µå+CSSé€‰æ‹©å™¨ï¼‰
- âœ… é¡µç èŒƒå›´ï¼ˆå¯é€‰ï¼‰
- âœ… ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨ï¼ˆå¯é€‰ï¼‰
- âœ… åˆ‡æ¢é¡µé¢å»¶è¿Ÿæ—¶é—´

### è¾“å‡ºæ ¼å¼
- âœ… JSONæ ¼å¼ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶

### æ ¸å¿ƒåŠŸèƒ½
1. âœ… ç”¨æˆ·æŒ‡å®šURLå’ŒCSSé€‰æ‹©å™¨
2. âœ… è§£æé¡µé¢DOMï¼Œè·å–æŒ‡å®šä¿¡æ¯
3. âœ… æ”¯æŒåˆ†é¡µé‡‡é›†
4. âœ… å¯é…ç½®å»¶è¿Ÿæ—¶é—´å’Œé¡µæ•°

---

## ğŸš€ å¿«é€Ÿä½¿ç”¨

### ä½ çš„ç¤ºä¾‹éœ€æ±‚

**è¾“å…¥**ï¼š
```
æ‰“å¼€ https://segmentfault.com/ é¡µé¢ï¼Œ
è·å– .list-group.list-group-flush å¯¹åº”çš„åˆ—è¡¨æ•°æ®ï¼Œ

é‡‡é›†çš„ä¿¡æ¯å’Œå¯¹åº”çš„é€‰æ‹©å™¨å¦‚ä¸‹ï¼š
æ ‡é¢˜ï¼šh3 a.text-body
æŠ•ç¥¨æ•°é‡ï¼š.num-card .font-size-16
é˜…è¯»æ•°é‡ï¼š.num-card.text-secondary .font-size-16

ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨æ˜¯ a.page-link[rel='next']ï¼Œ
é¡µé¢è‡³å°‘åœç•™5ç§’
```

**å®ç°ä»£ç **ï¼š

```python
import asyncio
from browser import BrowserManager
from puppeteer import UniversalScraper, create_scraper_config

async def main():
    async with BrowserManager(mode="launch") as bm:
        page = await bm.get_or_create_page()
        
        config = create_scraper_config(
            url="https://segmentfault.com/",
            fields={
                "æ ‡é¢˜": "h3 a.text-body",
                "æŠ•ç¥¨æ•°é‡": ".num-card .font-size-16",
                "é˜…è¯»æ•°é‡": ".num-card.text-secondary .font-size-16"
            },
            container_selector=".list-group.list-group-flush > .list-group-item",
            next_button_selector="a.page-link[rel='next']",
            delay=5.0,
            max_pages=2
        )
        
        scraper = UniversalScraper(page, config)
        data = await scraper.scrape()
        
        # ä¿å­˜ä¸ºä½ éœ€è¦çš„æ ¼å¼
        import json
        with open("output.json", 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

asyncio.run(main())
```

**è¾“å‡º**ï¼ˆoutput.jsonï¼‰ï¼š
```json
[
  {
    "æ ‡é¢˜": "xxx",
    "æŠ•ç¥¨æ•°é‡": "3",
    "é˜…è¯»æ•°é‡": "10"
  },
  {
    "æ ‡é¢˜": "yyy",
    "æŠ•ç¥¨æ•°é‡": "5",
    "é˜…è¯»æ•°é‡": "20"
  }
]
```

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
lib/puppeteer/universal_scraper/
â”œâ”€â”€ __init__.py           # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ scraper.py            # æ ¸å¿ƒæŠ“å–å™¨
â”œâ”€â”€ tools.py              # LangChainå·¥å…·é›†æˆ
â””â”€â”€ example.py            # å®Œæ•´ç¤ºä¾‹ï¼ˆ6ä¸ªåœºæ™¯ï¼‰

examples/
â””â”€â”€ universal_scraper_agent.py  # Agenté›†æˆç¤ºä¾‹

docs/
â””â”€â”€ universal_scraper_guide.md  # è¯¦ç»†ä½¿ç”¨æ–‡æ¡£

test_universal_scraper.py        # å¿«é€Ÿæµ‹è¯•è„šæœ¬
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### æ–¹æ³•1ï¼šè¿è¡Œæµ‹è¯•è„šæœ¬

```bash
python test_universal_scraper.py
# é€‰æ‹© 1 (åŸºç¡€æŠ“å–)
```

### æ–¹æ³•2ï¼šè¿è¡Œç¤ºä¾‹ä»£ç 

```bash
python lib/puppeteer/universal_scraper/example.py
# é€‰æ‹© 6 (å®Œæ•´ç”¨æˆ·åœºæ™¯)
```

### æ–¹æ³•3ï¼šä½¿ç”¨Agent

```bash
python examples/universal_scraper_agent.py
# é€‰æ‹© 1 (SegmentFaultä»»åŠ¡)
```

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. çµæ´»çš„å­—æ®µé…ç½®

```python
fields = {
    "æ ‡é¢˜": "h3 a.text-body",
    "æŠ•ç¥¨æ•°": ".vote-count",
    "é˜…è¯»æ•°": ".view-count"
}
```

### 2. å¤šç§åˆ†é¡µæ–¹å¼

```python
# æŒ‰é’®åˆ†é¡µ
next_button_selector = "button.next"

# URLå‚æ•°åˆ†é¡µ
page_range = (1, 10)

# é¡µç é“¾æ¥
next_button_selector = "a.page-link[rel='next']"
```

### 3. æ™ºèƒ½å»¶è¿Ÿæ§åˆ¶

```python
delay = 5.0  # æ¯é¡µç­‰å¾…5ç§’
```

### 4. é¡µæ•°é™åˆ¶

```python
max_pages = 10  # æœ€å¤šæŠ“å–10é¡µ
page_range = (3, 8)  # åªæŠ“å–ç¬¬3-8é¡µ
```

### 5. æå–å±æ€§å€¼

```python
FieldConfig(name="é“¾æ¥", selector="a", attribute="href")
FieldConfig(name="å›¾ç‰‡", selector="img", attribute="src")
```

---

## ğŸ¨ ä½¿ç”¨åœºæ™¯

| åœºæ™¯ | é…ç½® |
|------|------|
| å•é¡µæŠ“å– | åªè®¾ç½®`url`å’Œ`fields` |
| æŒ‰é’®åˆ†é¡µ | æ·»åŠ `next_button_selector` |
| URLåˆ†é¡µ | è®¾ç½®`page_range` |
| æå–é“¾æ¥ | ä½¿ç”¨`attribute="href"` |
| æµ‹è¯•é€‰æ‹©å™¨ | ä½¿ç”¨`preview_scrape`å·¥å…· |

---

## ğŸ“š æ–‡æ¡£

è¯¦ç»†æ–‡æ¡£ï¼š`docs/universal_scraper_guide.md`

åŒ…å«å†…å®¹ï¼š
- ğŸ“– å®Œæ•´å‚æ•°è¯´æ˜
- ğŸ’¡ æœ€ä½³å®è·µ
- ğŸ› å¸¸è§é—®é¢˜è§£ç­”
- ğŸ”§ è°ƒè¯•æŠ€å·§
- ğŸ“ æ›´å¤šç¤ºä¾‹

---

## ğŸ› ï¸ ä¸Agenté›†æˆ

### å¯ç”¨å·¥å…·

| å·¥å…· | åŠŸèƒ½ |
|------|------|
| `scrape_web_data` | åŸºç¡€é€šç”¨æŠ“å– |
| `scrape_web_data_advanced` | é«˜çº§æŠ“å–ï¼ˆæ”¯æŒé¡µç èŒƒå›´ï¼‰ |
| `preview_scrape` | é¢„è§ˆç»“æœï¼ˆæµ‹è¯•é€‰æ‹©å™¨ï¼‰ |

### Agentä½¿ç”¨ç¤ºä¾‹

```python
from custom_agent import create_custom_agent
from puppeteer import get_browser_tools, get_universal_scraping_tools

# è·å–æ‰€æœ‰å·¥å…·
all_tools = get_browser_tools(browser) + get_universal_scraping_tools(browser)

# åˆ›å»ºAgent
agent = create_custom_agent(tools=all_tools)

# æ‰§è¡Œä»»åŠ¡
task = """
æŠ“å– SegmentFault é¦–é¡µæ–‡ç« ï¼š
- å®¹å™¨: .list-group-item
- å­—æ®µ: {"æ ‡é¢˜": "h3 a", "æŠ•ç¥¨æ•°": ".vote"}
- æŠ“å–2é¡µï¼Œåœç•™5ç§’
"""
result = await agent.ainvoke({"messages": [HumanMessage(task)]})
```

---

## âœ¨ ç‰¹æ€§äº®ç‚¹

1. **é›¶ä¾èµ–é¢å¤–é…ç½®** - åŸºäºç°æœ‰é¡¹ç›®æ¶æ„
2. **å®Œå…¨ç±»å‹å®‰å…¨** - ä½¿ç”¨dataclasså’Œç±»å‹æ³¨è§£
3. **å¼‚å¸¸å¤„ç†å®Œå–„** - ä¼˜é›…å¤„ç†å„ç§é”™è¯¯æƒ…å†µ
4. **è¾“å‡ºæ ¼å¼çµæ´»** - æ”¯æŒå®Œæ•´/ç®€åŒ–JSONæ ¼å¼
5. **Agentå‹å¥½** - æ— ç¼é›†æˆLangChain
6. **æ–‡æ¡£é½å…¨** - ç¤ºä¾‹ä»£ç +è¯¦ç»†æ–‡æ¡£

---

## ğŸ” ä¸å…¶ä»–å·¥å…·å¯¹æ¯”

| ç‰¹æ€§ | Universal Scraper | Table Scraper | Puppeteer Tools |
|------|-------------------|---------------|-----------------|
| è‡ªå®šä¹‰å­—æ®µ | âœ… | âŒ | âŒ |
| æ ‡å‡†è¡¨æ ¼ | âœ… | âœ… | âŒ |
| éè¡¨æ ¼ç»“æ„ | âœ… | âŒ | âš ï¸ |
| åˆ†é¡µæ”¯æŒ | âœ… | âœ… | âŒ |
| é¡µç æ§åˆ¶ | âœ… | âš ï¸ | âŒ |
| æå–å±æ€§ | âœ… | âŒ | âŒ |
| Agenté›†æˆ | âœ… | âœ… | âœ… |

---

## ğŸ“ å­¦ä¹ è·¯å¾„

1. **æ–°æ‰‹**ï¼š
   - é˜…è¯»æœ¬README
   - è¿è¡Œ`test_universal_scraper.py`
   - å°è¯•ä¿®æ”¹ç¤ºä¾‹å‚æ•°

2. **è¿›é˜¶**ï¼š
   - æŸ¥çœ‹`example.py`ä¸­çš„6ä¸ªç¤ºä¾‹
   - å°è¯•æŠ“å–è‡ªå·±æ„Ÿå…´è¶£çš„ç½‘ç«™
   - å­¦ä¹ é«˜çº§å­—æ®µé…ç½®

3. **ä¸“å®¶**ï¼š
   - é˜…è¯»`docs/universal_scraper_guide.md`
   - é›†æˆåˆ°Agentå·¥ä½œæµ
   - è‡ªå®šä¹‰æ‰©å±•åŠŸèƒ½

---

## ğŸ“ æ”¯æŒ

- ğŸ“– è¯¦ç»†æ–‡æ¡£ï¼š`docs/universal_scraper_guide.md`
- ğŸ’¡ ç¤ºä¾‹ä»£ç ï¼š`lib/puppeteer/universal_scraper/example.py`
- ğŸ§ª æµ‹è¯•è„šæœ¬ï¼š`test_universal_scraper.py`
- ğŸ¤– Agentç¤ºä¾‹ï¼š`examples/universal_scraper_agent.py`

---

## ğŸ‰ æ€»ç»“

ä½ çš„éœ€æ±‚å·²ç»**å®Œå…¨å®ç°**ï¼

âœ… **å…¥å‚**ï¼šurlã€å­—æ®µé…ç½®ã€åˆ†é¡µé€‰æ‹©å™¨ã€å»¶è¿Ÿæ—¶é—´ã€é¡µæ•°  
âœ… **åŠŸèƒ½**ï¼šDOMè§£æã€æ•°æ®æå–ã€åˆ†é¡µé‡‡é›†  
âœ… **è¾“å‡º**ï¼šæ ‡å‡†JSONæ ¼å¼

ç«‹å³å¼€å§‹ä½¿ç”¨ï¼š
```bash
python test_universal_scraper.py
```
