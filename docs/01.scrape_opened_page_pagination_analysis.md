# åœ¨å·²æ‰“å¼€çš„é¡µé¢ä¸Šè¿›è¡Œåˆ†é¡µæŠ“å– - é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## ğŸ” é—®é¢˜åˆ†æ

### æ–‡ä»¶ 1: `test/test_universal_scraper_opened.py`

**é—®é¢˜**ï¼š
```python
# test_with_scraper() å‡½æ•°ä¸­
data = await scraper.scrape_current_page()  # âŒ åªæŠ“å–å½“å‰é¡µ
```

- âœ… æˆåŠŸè¿æ¥åˆ°å·²æ‰“å¼€çš„é¡µé¢
- âŒ **åªæŠ“å–äº†å½“å‰é¡µé¢ï¼Œæ²¡æœ‰è¿›è¡Œåˆ†é¡µ**
- âŒ æ²¡æœ‰åˆ©ç”¨ `scrape_with_pagination()` æ–¹æ³•

---

### æ–‡ä»¶ 2: `lib/puppeteer/universal_scraper/scraper.py`

**åŸæœ‰æ–¹æ³•**ï¼š

```python
async def scrape(self) -> List[Dict[str, Any]]:
    # ä¼šé‡æ–°å¯¼èˆªåˆ°URL
    await self.page.goto(self.config.url)  # âŒ ä¸¢å¤±å½“å‰é¡µé¢çŠ¶æ€
    await asyncio.sleep(self.config.delay)
    
    if self.config.next_button_selector:
        return await self.scrape_with_pagination()
```

**é—®é¢˜**ï¼š
- `scrape()` æ–¹æ³•ä¼šå…ˆå¯¼èˆªï¼ˆ`page.goto()`ï¼‰
- å¯¹äºå·²æ‰“å¼€çš„é¡µé¢ï¼Œè¿™ä¼š**é‡æ–°åŠ è½½é¡µé¢**
- **ä¸¢å¤±å½“å‰çŠ¶æ€**ï¼ˆå¦‚æœç´¢ç»“æœã€ç™»å½•çŠ¶æ€ç­‰ï¼‰

---

## âœ… è§£å†³æ–¹æ¡ˆ

### 1. æ–°å¢æ–¹æ³•ï¼š`scrape_from_current_page()`

**ä½ç½®**ï¼š`lib/puppeteer/universal_scraper/scraper.py`

```python
async def scrape_from_current_page(self, skip_navigation: bool = True):
    """
    ä»å½“å‰é¡µé¢å¼€å§‹æŠ“å–ï¼ˆä¸å¯¼èˆªï¼‰
    é€‚ç”¨äºå·²ç»æ‰“å¼€çš„é¡µé¢
    """
    print(f"ğŸ“ ä»å½“å‰é¡µé¢å¼€å§‹æŠ“å–: {self.page.url}")
    
    # ç­‰å¾…é¡µé¢ç¨³å®š
    await asyncio.sleep(self.config.delay)
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†é¡µ
    if self.config.next_button_selector or self.config.page_range:
        return await self.scrape_with_pagination()  # â­ æ”¯æŒåˆ†é¡µ
    else:
        data = await self.scrape_current_page()
        self.all_data = data
        return data
```

**ç‰¹ç‚¹**ï¼š
- âœ… ä¸ä¼šé‡æ–°å¯¼èˆª
- âœ… ä¿ç•™å½“å‰é¡µé¢çŠ¶æ€
- âœ… æ”¯æŒåˆ†é¡µæŠ“å–
- âœ… é€‚ç”¨äºå·²æ‰“å¼€çš„é¡µé¢

---

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### åœºæ™¯ï¼šåœ¨å·²æ‰“å¼€çš„ SegmentFault æœç´¢ç»“æœé¡µä¸Šåˆ†é¡µæŠ“å–

```python
import asyncio
from browser import BrowserManager
from puppeteer import UniversalScraper, create_scraper_config

async def main():
    async with BrowserManager(mode="connect") as bm:
        # 1. è¿æ¥åˆ°å·²æ‰“å¼€çš„é¡µé¢
        page = await bm.get_or_create_page(target_url="segmentfault.com")
        
        # 2. é…ç½®æŠ“å–å™¨ï¼ˆæ”¯æŒåˆ†é¡µï¼‰
        config = create_scraper_config(
            url=page.url,
            fields={
                "æ ‡é¢˜": "h5",
                "æ—¶é—´": ".mb-0.font-size-14"
            },
            container_selector=".row div.list-group li",
            next_button_selector=".d-none .page-item:last-child .page-link",  # ä¸‹ä¸€é¡µ
            max_pages=2,  # æŠ“å–2é¡µ
            delay=3.0
        )
        
        # 3. åˆ›å»ºæŠ“å–å™¨
        scraper = UniversalScraper(page, config)
        
        # 4. â­ å…³é”®ï¼šä½¿ç”¨ scrape_from_current_page()
        data = await scraper.scrape_from_current_page()
        
        # 5. ä¿å­˜æ•°æ®
        scraper.save_to_json("result.json")
        print(f"âœ… æˆåŠŸæŠ“å– {len(data)} æ¡æ•°æ®")

asyncio.run(main())
```

---

## ğŸ“Š æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æ˜¯å¦å¯¼èˆª | é€‚ç”¨åœºæ™¯ | ä¿ç•™çŠ¶æ€ | æ”¯æŒåˆ†é¡µ |
|------|----------|----------|----------|----------|
| `scrape()` | âœ… æ˜¯ | æ–°é¡µé¢ | âŒ å¦ | âœ… æ˜¯ |
| `scrape_from_current_page()` | âŒ å¦ | å·²æ‰“å¼€çš„é¡µé¢ | âœ… æ˜¯ | âœ… æ˜¯ |
| `scrape_current_page()` | âŒ å¦ | å•é¡µ | âœ… æ˜¯ | âŒ å¦ |

---

## ğŸ”„ å·¥ä½œæµç¨‹

### åŸå§‹æ–¹æ³•ï¼ˆ`scrape()`ï¼‰ï¼š

```
1. å¯¼èˆªåˆ°URL (page.goto)  â† ä¸¢å¤±å½“å‰çŠ¶æ€
2. ç­‰å¾…é¡µé¢åŠ è½½
3. æŠ“å–å½“å‰é¡µ
4. ç‚¹å‡»ä¸‹ä¸€é¡µ
5. é‡å¤æ­¥éª¤3-4
```

### æ–°æ–¹æ³•ï¼ˆ`scrape_from_current_page()`ï¼‰ï¼š

```
1. ä½¿ç”¨å½“å‰é¡µé¢ï¼ˆä¸å¯¼èˆªï¼‰  â† ä¿ç•™çŠ¶æ€
2. ç­‰å¾…é¡µé¢ç¨³å®š
3. æŠ“å–å½“å‰é¡µ
4. ç‚¹å‡»ä¸‹ä¸€é¡µ
5. é‡å¤æ­¥éª¤3-4
```

---

## ğŸ’¡ å®é™…åº”ç”¨åœºæ™¯

### åœºæ™¯ 1: æœç´¢ç»“æœåˆ†é¡µ

**éœ€æ±‚**ï¼šåœ¨ SegmentFault æœç´¢ "langchain" åï¼ŒæŠ“å–æœç´¢ç»“æœçš„å‰3é¡µ

```python
# 1. å…ˆåœ¨æµè§ˆå™¨ä¸­æœç´¢
# 2. ç„¶åè¿è¡Œè„šæœ¬è¿æ¥åˆ°æœç´¢ç»“æœé¡µ
# 3. ä½¿ç”¨ scrape_from_current_page() åˆ†é¡µæŠ“å–

config = create_scraper_config(
    url=page.url,  # æœç´¢ç»“æœé¡µçš„URL
    fields={"æ ‡é¢˜": "h5", "æ—¶é—´": ".date"},
    container_selector=".list-item",
    next_button_selector=".next-page",
    max_pages=3
)

data = await scraper.scrape_from_current_page()
```

---

### åœºæ™¯ 2: ç™»å½•åçš„æ•°æ®

**éœ€æ±‚**ï¼šæŠ“å–éœ€è¦ç™»å½•æ‰èƒ½çœ‹åˆ°çš„å†…å®¹

```python
# 1. æ‰‹åŠ¨ç™»å½•
# 2. å¯¼èˆªåˆ°ç›®æ ‡é¡µé¢
# 3. è¿è¡Œè„šæœ¬è¿æ¥
# 4. åˆ†é¡µæŠ“å–ï¼ˆä¿æŒç™»å½•çŠ¶æ€ï¼‰

data = await scraper.scrape_from_current_page()
```

---

### åœºæ™¯ 3: åŠ¨æ€ç­›é€‰åçš„æ•°æ®

**éœ€æ±‚**ï¼šåœ¨é¡µé¢ä¸Šè¿›è¡Œç­›é€‰åï¼ŒæŠ“å–ç­›é€‰ç»“æœ

```python
# 1. æ‰‹åŠ¨è®¾ç½®ç­›é€‰æ¡ä»¶
# 2. è¿è¡Œè„šæœ¬è¿æ¥
# 3. åˆ†é¡µæŠ“å–ç­›é€‰åçš„æ•°æ®

data = await scraper.scrape_from_current_page()
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1: å¯åŠ¨ Chrome

```bash
chrome.exe --remote-debugging-port=9222
```

### æ­¥éª¤ 2: æ‰“å¼€ç›®æ ‡é¡µé¢

åœ¨ Chrome ä¸­ï¼š
1. è®¿é—® https://segmentfault.com/
2. æœç´¢å…³é”®è¯ï¼ˆå¦‚ "langchain"ï¼‰
3. ç‚¹å‡»"æ–‡ç« "æ ‡ç­¾
4. åœç•™åœ¨æœç´¢ç»“æœé¡µ

### æ­¥éª¤ 3: è¿è¡Œè„šæœ¬

```bash
python examples/scrape_opened_page_pagination.py
# é€‰æ‹© 1 â†’ åœ¨å·²æ‰“å¼€é¡µé¢ä¸Šåˆ†é¡µæŠ“å–
```

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `lib/puppeteer/universal_scraper/scraper.py` | æ ¸å¿ƒæŠ“å–å™¨ï¼ˆå·²æ›´æ–°ï¼‰ |
| `examples/scrape_opened_page_pagination.py` | å®Œæ•´ç¤ºä¾‹ |
| `test/test_universal_scraper_opened.py` | åŸæµ‹è¯•æ–‡ä»¶ |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å¿…é¡»ä½¿ç”¨ connect æ¨¡å¼

```python
# âœ… æ­£ç¡®
async with BrowserManager(mode="connect") as bm:
    ...

# âŒ é”™è¯¯ï¼ˆlaunch æ¨¡å¼æ²¡æœ‰å·²æ‰“å¼€çš„é¡µé¢ï¼‰
async with BrowserManager(mode="launch") as bm:
    ...
```

### 2. ç¡®è®¤é¡µé¢å·²åŠ è½½å®Œæˆ

```python
# å¦‚æœé¡µé¢è¿˜åœ¨åŠ è½½ï¼Œå¢åŠ å»¶è¿Ÿ
config.delay = 5.0  # å¢åŠ åˆ°5ç§’
```

### 3. éªŒè¯é€‰æ‹©å™¨æ˜¯å¦æ­£ç¡®

```python
# ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·éªŒè¯ï¼š
# 1. å®¹å™¨é€‰æ‹©å™¨
# 2. å­—æ®µé€‰æ‹©å™¨
# 3. ä¸‹ä¸€é¡µæŒ‰é’®é€‰æ‹©å™¨
```

---

## ğŸ‰ æ€»ç»“

**é—®é¢˜**ï¼š
- åŸä»£ç åªæŠ“å–å½“å‰é¡µï¼Œä¸æ”¯æŒåˆ†é¡µ
- `scrape()` æ–¹æ³•ä¼šé‡æ–°å¯¼èˆªï¼Œä¸¢å¤±çŠ¶æ€

**è§£å†³æ–¹æ¡ˆ**ï¼š
- âœ… æ–°å¢ `scrape_from_current_page()` æ–¹æ³•
- âœ… ä¸ä¼šé‡æ–°å¯¼èˆªï¼Œä¿ç•™é¡µé¢çŠ¶æ€
- âœ… æ”¯æŒåˆ†é¡µæŠ“å–
- âœ… å®Œæ•´çš„ç¤ºä¾‹ä»£ç 

**ä½¿ç”¨å»ºè®®**ï¼š
- æ–°é¡µé¢ â†’ ä½¿ç”¨ `scrape()`
- å·²æ‰“å¼€çš„é¡µé¢ â†’ ä½¿ç”¨ `scrape_from_current_page()`
- å•é¡µæŠ“å– â†’ ä½¿ç”¨ `scrape_current_page()`

ç«‹å³å¼€å§‹ä½¿ç”¨ï¼š
```bash
python examples/scrape_opened_page_pagination.py
```
